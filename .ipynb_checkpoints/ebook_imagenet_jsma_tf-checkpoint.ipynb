{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介绍如何在tensorflow环境下，使用JSMA算法攻击基于Inception数据集预训练的alexnet模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebook中使用Anaconda中的环境需要单独配置，默认情况下使用的是系统默认的Python环境，以使用advbox环境为例。\n",
    "首先在默认系统环境下执行以下命令，安装ipykernel。\n",
    "\n",
    "    conda install ipykernel\n",
    "    conda install -n advbox ipykernel\n",
    "\n",
    "在advbox环境下激活，这样启动后就可以在界面上看到advbox了。\n",
    "\n",
    "    python -m ipykernel install --user --name advbox --display-name advbox \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,format=\"%(filename)s[line:%(lineno)d] %(levelname)s %(message)s\")\n",
    "logger=logging.getLogger(__name__)\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#pip install Pillow\n",
    "from advbox.adversary import Adversary\n",
    "from advbox.attacks.saliency import JSMA\n",
    "from advbox.models.tensorflow import TensorflowModel\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tools import show_images_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义被攻击的图片\n",
    "imagename=\"tutorials/cropped_panda.jpg\"\n",
    "#从'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'下载并解压到当前路径\n",
    "dirname=\"classify_image_graph_def.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow.py[line:63] INFO self._input_shape:(Dimension(None), Dimension(None), Dimension(3))\n",
      "tensorflow.py[line:65] INFO init grads[1008]...\n",
      "tensorflow.py[line:72] INFO Finish TensorflowPBModel init\n",
      "base.py[line:87] INFO adversary:\n",
      "         original_label: 169\n",
      "         target_label: 651\n",
      "         is_targeted_attack: True\n",
      "saliency.py[line:89] INFO step = 0, original_label = 169, adv_label=169 target logit=0.797315359116\n",
      "tensorflow.py[line:127] INFO Start to get _grads[651]\n",
      "tensorflow.py[line:129] INFO Finish to get _grads[651]\n",
      "saliency.py[line:89] INFO step = 1, original_label = 169, adv_label=169 target logit=0.79630959034\n",
      "saliency.py[line:89] INFO step = 2, original_label = 169, adv_label=169 target logit=0.825366795063\n",
      "saliency.py[line:89] INFO step = 3, original_label = 169, adv_label=169 target logit=0.834807634354\n",
      "saliency.py[line:89] INFO step = 4, original_label = 169, adv_label=169 target logit=0.872357845306\n",
      "saliency.py[line:89] INFO step = 5, original_label = 169, adv_label=169 target logit=0.861105322838\n",
      "saliency.py[line:89] INFO step = 6, original_label = 169, adv_label=169 target logit=0.880670785904\n",
      "saliency.py[line:89] INFO step = 7, original_label = 169, adv_label=169 target logit=0.893260121346\n",
      "saliency.py[line:89] INFO step = 8, original_label = 169, adv_label=169 target logit=0.902770996094\n",
      "saliency.py[line:89] INFO step = 9, original_label = 169, adv_label=169 target logit=0.910962462425\n",
      "saliency.py[line:89] INFO step = 10, original_label = 169, adv_label=169 target logit=0.911954045296\n",
      "saliency.py[line:89] INFO step = 11, original_label = 169, adv_label=169 target logit=0.910098671913\n",
      "saliency.py[line:89] INFO step = 12, original_label = 169, adv_label=169 target logit=0.928460121155\n",
      "saliency.py[line:89] INFO step = 13, original_label = 169, adv_label=169 target logit=0.937087655067\n",
      "saliency.py[line:89] INFO step = 14, original_label = 169, adv_label=169 target logit=0.939061760902\n",
      "saliency.py[line:89] INFO step = 15, original_label = 169, adv_label=169 target logit=0.935366749763\n",
      "saliency.py[line:89] INFO step = 16, original_label = 169, adv_label=169 target logit=0.943362474442\n",
      "saliency.py[line:89] INFO step = 17, original_label = 169, adv_label=169 target logit=0.955797553062\n",
      "saliency.py[line:89] INFO step = 18, original_label = 169, adv_label=169 target logit=0.955365657806\n",
      "saliency.py[line:89] INFO step = 19, original_label = 169, adv_label=169 target logit=0.967956066132\n",
      "saliency.py[line:89] INFO step = 20, original_label = 169, adv_label=169 target logit=0.984808087349\n",
      "saliency.py[line:89] INFO step = 21, original_label = 169, adv_label=169 target logit=0.977769494057\n",
      "saliency.py[line:89] INFO step = 22, original_label = 169, adv_label=169 target logit=0.989832758904\n",
      "saliency.py[line:89] INFO step = 23, original_label = 169, adv_label=169 target logit=0.991804599762\n",
      "saliency.py[line:89] INFO step = 24, original_label = 169, adv_label=169 target logit=0.980811476707\n",
      "saliency.py[line:89] INFO step = 25, original_label = 169, adv_label=169 target logit=1.00092792511\n",
      "saliency.py[line:89] INFO step = 26, original_label = 169, adv_label=169 target logit=1.01117253304\n",
      "saliency.py[line:89] INFO step = 27, original_label = 169, adv_label=169 target logit=1.00463438034\n",
      "saliency.py[line:89] INFO step = 28, original_label = 169, adv_label=169 target logit=1.01204669476\n",
      "saliency.py[line:89] INFO step = 29, original_label = 169, adv_label=169 target logit=1.01494061947\n",
      "saliency.py[line:89] INFO step = 30, original_label = 169, adv_label=169 target logit=1.03516292572\n",
      "saliency.py[line:89] INFO step = 31, original_label = 169, adv_label=169 target logit=1.03273749352\n",
      "saliency.py[line:89] INFO step = 32, original_label = 169, adv_label=169 target logit=1.02976953983\n",
      "saliency.py[line:89] INFO step = 33, original_label = 169, adv_label=169 target logit=1.05067658424\n",
      "saliency.py[line:89] INFO step = 34, original_label = 169, adv_label=169 target logit=1.04751515388\n",
      "saliency.py[line:89] INFO step = 35, original_label = 169, adv_label=169 target logit=1.04507553577\n",
      "saliency.py[line:89] INFO step = 36, original_label = 169, adv_label=169 target logit=1.06053423882\n",
      "saliency.py[line:89] INFO step = 37, original_label = 169, adv_label=169 target logit=1.02811896801\n",
      "saliency.py[line:89] INFO step = 38, original_label = 169, adv_label=169 target logit=1.0645250082\n",
      "saliency.py[line:89] INFO step = 39, original_label = 169, adv_label=169 target logit=1.05913436413\n"
     ]
    }
   ],
   "source": [
    "#加载解码的图像 这里是个大坑 tf提供的imagenet预训练好的模型pb文件中 包含针对图像的预处理环节 即解码jpg文件 这部分没有梯度\n",
    "#需要直接处理解码后的数据\n",
    "image=np.array(Image.open(imagename).convert('RGB').resize((224,224))).astype(np.float32)\n",
    "#[100,100,3]->[1,100,100,3]\n",
    "\n",
    "orig=image.copy().astype(np.uint8) \n",
    "\n",
    "image=np.expand_dims(image, axis=0)\n",
    "\n",
    "  \n",
    "\n",
    "session=tf.Session()\n",
    "\n",
    "def create_graph(dirname):\n",
    "    with tf.gfile.FastGFile(dirname, 'rb') as f:\n",
    "        graph_def = session.graph_def\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "create_graph(dirname)\n",
    "\n",
    "# 初始化参数  非常重要\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "tensorlist=[n.name for n in session.graph_def.node]\n",
    "\n",
    "#输出全部tensor\n",
    "#logger.info(tensorlist)\n",
    "\n",
    "\n",
    "#获取logits\n",
    "logits=session.graph.get_tensor_by_name('softmax/logits:0')\n",
    "\n",
    "x = session.graph.get_tensor_by_name('ExpandDims:0')\n",
    "\n",
    "# advbox demo\n",
    "# 因为原始数据没有归一化  所以bounds=(0, 255)\n",
    "m = TensorflowModel(\n",
    "    session,\n",
    "    x,\n",
    "    None,\n",
    "    logits,\n",
    "    None,\n",
    "    bounds=(0, 255),\n",
    "    channel_axis=3,\n",
    "    preprocess=None)\n",
    "\n",
    "#实例化JSMA max_iter为最大迭代次数  theta为扰动系数 max_perturbations_per_pixel为单像素最大修改次数\n",
    "attack = JSMA(m)\n",
    "attack_config = {\n",
    "        \"max_iter\": 2000,\n",
    "        \"theta\": 0.1,\n",
    "        \"max_perturbations_per_pixel\": 7,\n",
    "        \"fast\":True,\n",
    "        \"two_pix\":False\n",
    "}\n",
    "\n",
    "\n",
    "adversary = Adversary(image,None)\n",
    "#麦克风\n",
    "tlabel = 651\n",
    "adversary.set_target(is_targeted_attack=True, target_label=tlabel)\n",
    "\n",
    "# FGSM targeted attack\n",
    "adversary = attack(adversary, **attack_config)\n",
    "\n",
    "if adversary.is_successful():\n",
    "    print(\n",
    "        'attack success, adversarial_label=%d'\n",
    "        % (adversary.adversarial_label) )\n",
    "\n",
    "    #对抗样本保存在adversary.adversarial_example\n",
    "    adversary_image=np.copy(adversary.adversarial_example)\n",
    "    #强制类型转换 之前是float 现在要转换成int8\n",
    "\n",
    "    adv = np.array(adversary_image).astype(\"uint8\")[0]\n",
    "\n",
    " \n",
    "\n",
    "print(\"jsma attack done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#显示原始图片  抵抗样本 以及两张图之间的差异  其中灰色代表没有差异的像素点\n",
    "show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advbox",
   "language": "python",
   "name": "advbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
